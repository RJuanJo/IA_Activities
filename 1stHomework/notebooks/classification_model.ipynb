{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**L1 and L2 Regularization:**\n",
    "\n",
    "Regularization is used in machine learning models to prevent overfitting and improve model generalization. There are two main types of regularization: L1 and L2.\n",
    "\n",
    "**L1 Regularization (Lasso):**\n",
    "\n",
    "- **Description:** L1 regularization adds a penalty equal to the sum of the absolute values of the model coefficients. This penalty is the sum of the absolute values of the coefficients multiplied by a regularization parameter (λ).\n",
    "- **Effect:** L1 regularization can make some coefficients exactly zero. This can lead to automatic feature selection by eliminating some variables from the model.\n",
    "- **Implementation in scikit-learn:** To use L1 in `LogisticRegression`, you should set the parameter `penalty='l1'`. However, some solvers (such as `'liblinear'`) support L1 in scikit-learn.\n",
    "\n",
    "   ```python\n",
    "   from sklearn.linear_model import LogisticRegression\n",
    "   model = LogisticRegression(penalty='l1', solver='liblinear')\n",
    "   model.fit(X_train, y_train)\n",
    "   ```\n",
    "\n",
    "**L2 Regularization (Ridge):**\n",
    "\n",
    "- **Description:** L2 regularization adds a penalty equal to the sum of the squares of the model coefficients. This penalty is the sum of the squares of the coefficients multiplied by a regularization parameter (λ).\n",
    "- **Effect:** L2 regularization tends to reduce coefficients more uniformly, avoiding extremely large values and promoting smaller, more evenly distributed coefficients. It does not tend to make coefficients exactly zero.\n",
    "- **Implementation in scikit-learn:** To use L2 in `LogisticRegression`, you should set the parameter `penalty='l2'`. This is the default option in scikit-learn.\n",
    "\n",
    "   ```python\n",
    "   from sklearn.linear_model import LogisticRegression\n",
    "   model = LogisticRegression(penalty='l2')\n",
    "   model.fit(X_train, y_train)\n",
    "   ```\n",
    "\n",
    "**Comparison between L1 and L2:**\n",
    "\n",
    "- **L1 Regularization:**\n",
    "  - **Advantages:** Performs feature selection by making some coefficients exactly zero. Useful when some features are suspected to be irrelevant.\n",
    "  - **Disadvantages:** Can be less stable in the presence of highly correlated features.\n",
    "\n",
    "- **L2 Regularization:**\n",
    "  - **Advantages:** Penalizes large coefficient values more smoothly and tends to provide more stable solutions. Useful when all features are expected to contribute to the model.\n",
    "  - **Disadvantages:** Does not perform feature selection, as it does not drive coefficients to zero.\n",
    "\n",
    "**Choice between L1 and L2:**\n",
    "- The choice between L1 and L2 depends on the nature of the data and the model’s goal. L1 is preferred when feature selection is needed, while L2 is useful for maintaining more uniform and stable coefficients.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Cross-Entropy Loss in Logistic Regression**\n",
    "\n",
    "**Description:**\n",
    "\n",
    "Cross-entropy loss, often referred to as log-loss, is a key concept used to measure how well a logistic regression model performs. It is specifically designed for classification problems where the model predicts probabilities that a given input belongs to a particular class.\n",
    "\n",
    "**How It Works:**\n",
    "\n",
    "- **Binary Classification:** In a binary classification problem (where there are two classes, like 'spam' and 'ham'), cross-entropy loss calculates how well the predicted probabilities match the actual class labels. The loss increases as the predicted probability diverges from the actual label. \n",
    "\n",
    "- **Multi-Class Classification:** For problems with more than two classes, cross-entropy loss generalizes to account for multiple possible categories. It evaluates how close the predicted probability distribution is to the actual distribution of the classes.\n",
    "\n",
    "**Role in Model Training:**\n",
    "\n",
    "- **Gradient Descent:** Logistic regression models use gradient descent to minimize the cross-entropy loss. This means the model iteratively adjusts its parameters to reduce the loss, improving the accuracy of its predictions.\n",
    "\n",
    "- **Model Adjustment:** During training, the model's parameters are updated based on the gradients of the loss function. This helps the model learn from errors and make better predictions.\n",
    "\n",
    "**Implementation in Scikit-Learn:**\n",
    "\n",
    "- **Default Behavior:** In `scikit-learn`, the `LogisticRegression` class automatically uses cross-entropy loss as the objective function during training. This ensures that the model is optimized to predict probabilities that are as close as possible to the true class labels.\n",
    "\n",
    "Here's a quick example of how to use logistic regression in `scikit-learn`:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Create a logistic regression model\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "--- \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Multi-Class Options in Logistic Regression**\n",
    "\n",
    "Logistic regression can be extended to handle multi-class classification problems, where there are more than two classes. Scikit-Learn provides several options for dealing with multi-class classification in the `LogisticRegression` class. These options are specified using the `multi_class` parameter.\n",
    "\n",
    "\n",
    "**1. `multi_class='ovr'` (One-vs-Rest)**\n",
    "\n",
    "- **Description:**\n",
    "  The One-vs-Rest (OvR) approach, also known as One-vs-All, involves training a separate binary classifier for each class. For each classifier, the class is treated as the positive class, and all other classes are treated as the negative class.\n",
    "\n",
    "- **How It Works:**\n",
    "  - For each class \\( c \\), a binary logistic regression model is trained to distinguish class \\( c \\) from all other classes.\n",
    "  - During prediction, the class with the highest probability from its respective binary classifier is selected as the predicted class.\n",
    "\n",
    "- **Implementation:**\n",
    "  By default, `LogisticRegression` uses the OvR approach when the `multi_class` parameter is set to `'ovr'`.\n",
    "\n",
    "  ```python\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "  model = LogisticRegression(multi_class='ovr')\n",
    "  model.fit(X_train, y_train)\n",
    "  ```\n",
    "\n",
    "\n",
    "**2. `multi_class='multinomial'`**\n",
    "\n",
    "- **Description:**\n",
    "  The Multinomial approach directly models the probability of each class using a single logistic regression model. It is based on the softmax function, which generalizes the sigmoid function used in binary classification to multiple classes.\n",
    "\n",
    "- **How It Works:**\n",
    "  - The multinomial logistic regression model estimates the probability of each class by considering all classes simultaneously.\n",
    "  - The softmax function is used to compute the probability of each class.\n",
    "\n",
    "- **Implementation:**\n",
    "  To use the multinomial approach, set the `multi_class` parameter to `'multinomial'` and use the `solver='lbfgs'`, `solver='saga'`, or `solver='newton-cg'` (as 'liblinear' does not support multinomial).\n",
    "\n",
    "  ```python\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "  model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "  model.fit(X_train, y_train)\n",
    "  ```\n",
    "\n",
    "\n",
    "**3. `multi_class='auto'`**\n",
    "\n",
    "- **Description:**\n",
    "  The `auto` option automatically selects the appropriate multi-class strategy based on the solver. If the solver supports multinomial classification, it will use that. Otherwise, it will default to the One-vs-Rest approach.\n",
    "\n",
    "- **Implementation:**\n",
    "  Simply set `multi_class='auto'` (which is also the default value).\n",
    "\n",
    "  ```python\n",
    "  from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "  model = LogisticRegression(multi_class='auto')\n",
    "  model.fit(X_train, y_train)\n",
    "  ```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**`solver='sag'` in Logistic Regression**\n",
    "\n",
    "**Description:**\n",
    "\n",
    "In logistic regression, the `solver` parameter specifies the algorithm used to optimize the cost function. One of the available options is `solver='sag'`, which stands for Stochastic Average Gradient. This solver is particularly designed to handle large datasets efficiently.\n",
    "\n",
    "**How It Works:**\n",
    "\n",
    "- **Stochastic Average Gradient (SAG):**\n",
    "  - The SAG algorithm is a variant of stochastic gradient descent (SGD) that enhances convergence speed and stability.\n",
    "  - Unlike traditional SGD, which updates the model parameters after each individual sample, SAG updates the parameters based on a running average of gradients over all samples.\n",
    "  - This method reduces the variance of gradient estimates, leading to more stable and faster convergence compared to standard SGD.\n",
    "\n",
    "**Advantages:**\n",
    "\n",
    "- **Efficiency:** SAG is particularly effective for large-scale datasets as it reduces the number of passes required over the data.\n",
    "- **Convergence Speed:** The averaging of gradients helps achieve faster convergence compared to standard SGD.\n",
    "\n",
    "**Implementation in Scikit-Learn:**\n",
    "\n",
    "To use the SAG solver in `scikit-learn`, set the `solver` parameter to `'sag'` when creating the `LogisticRegression` model. Note that the `saga` solver is often recommended as it combines the advantages of SAG and also supports L1 regularization.\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(solver='sag')\n",
    "model.fit(X_train, y_train)\n",
    "```\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**`SGDClassifier` in Scikit-Learn**\n",
    "\n",
    "**Description:**\n",
    "\n",
    "The `SGDClassifier` in `scikit-learn` is a linear classifier that utilizes stochastic gradient descent (SGD) for optimization. It is designed for handling large-scale and sparse datasets efficiently.\n",
    "\n",
    "**How It Works:**\n",
    "\n",
    "- **Stochastic Gradient Descent (SGD):**\n",
    "  - **SGD** is an optimization method used to minimize the loss function by iteratively updating model parameters.\n",
    "  - Unlike traditional gradient descent, which computes gradients and updates parameters using the entire dataset, SGD does so using a single data point or a small batch of data points at each iteration.\n",
    "  - This introduces randomness into the gradient computation, which can help in escaping local minima and speeding up convergence.\n",
    "\n",
    "- **Parameters:**\n",
    "  - **`loss`**: Specifies the loss function to minimize (e.g., `'hinge'` for SVM, `'log'` for logistic regression).\n",
    "  - **`penalty`**: Specifies the type of regularization to apply (e.g., `'l2'`, `'l1'`, or `'elasticnet'`).\n",
    "  - **`alpha`**: Regularization strength, with higher values indicating stronger regularization.\n",
    "  - **`learning_rate`**: Defines the learning rate schedule (e.g., `'constant'`, `'optimal'`, `'invscaling'`, `'adaptive'`).\n",
    "  - **`eta0`**: The initial learning rate (used with `'constant'` or `'adaptive'` learning rates).\n",
    "\n",
    "**Implementation in Scikit-Learn:**\n",
    "\n",
    "To use `SGDClassifier` in `scikit-learn`, configure it with the desired parameters. Here’s an example using logistic regression loss:\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "# Create an instance of SGDClassifier with logistic loss\n",
    "model = SGDClassifier(loss='log', penalty='l2', alpha=0.001, learning_rate='constant', eta0=0.01)\n",
    "\n",
    "# Fit the model to the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "```\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Encoding Categorical Data**\n",
    "\n",
    "**Description:**\n",
    "\n",
    "When working with machine learning models, categorical data must be converted into numerical formats. This allows algorithms to process the data effectively. There are several methods to encode categorical variables, each with its advantages and limitations.\n",
    "\n",
    "**Methods for Encoding Categorical Data:**\n",
    "\n",
    "1. **One-Hot Encoding:**\n",
    "   - **Description:** Converts categorical values into binary vectors. Each category is represented as a vector with a single '1' indicating the presence of the category and '0's elsewhere.\n",
    "   - **Advantages:**\n",
    "     - Avoids ordinality assumptions since no inherent order is implied.\n",
    "     - Works well with algorithms that require numerical input.\n",
    "   - **Disadvantages:**\n",
    "     - Can lead to high-dimensional feature space if the categorical variable has many levels.\n",
    "     - May introduce sparsity in the dataset.\n",
    "\n",
    "   ```python\n",
    "   from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "   encoder = OneHotEncoder(sparse=False)\n",
    "   X_encoded = encoder.fit_transform(df[['Category']])\n",
    "   ```\n",
    "\n",
    "2. **Label Encoding:**\n",
    "   - **Description:** Converts each category into a unique integer. Each category is assigned a unique integer value.\n",
    "   - **Advantages:**\n",
    "     - Simple to implement and does not increase feature dimensionality.\n",
    "   - **Disadvantages:**\n",
    "     - Implies an ordinal relationship between categories which may not be appropriate for all models.\n",
    "\n",
    "   ```python\n",
    "   from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "   encoder = LabelEncoder()\n",
    "   y_encoded = encoder.fit_transform(df['Category'])\n",
    "   ```\n",
    "\n",
    "3. **Ordinal Encoding:**\n",
    "   - **Description:** Assigns integer values to categories while preserving an ordinal relationship. Useful when there is a natural order between categories.\n",
    "   - **Advantages:**\n",
    "     - Preserves ordinal relationships and is less sparse compared to one-hot encoding.\n",
    "   - **Disadvantages:**\n",
    "     - The ordinal relationship may not always be meaningful, and it can mislead algorithms if the ordering is not correctly represented.\n",
    "\n",
    "   ```python\n",
    "   from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "   encoder = OrdinalEncoder()\n",
    "   X_encoded = encoder.fit_transform(df[['Category']])\n",
    "   ```\n",
    "\n",
    "**Choosing the Right Encoding Method:**\n",
    "\n",
    "- **One-Hot Encoding** is often preferred when categorical variables do not have an ordinal relationship and when dealing with models that can handle high-dimensional spaces.\n",
    "- **Label Encoding** is simpler but should be used with caution if the model could misinterpret the integer values as having an ordinal relationship.\n",
    "- **Ordinal Encoding** is suitable when the categorical variable has a meaningful order and you want to preserve this relationship in the numerical representation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Assignments Implementation & Training Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/spam.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing text\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text, flags=re.MULTILINE)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text\n",
    "\n",
    "df['Processed_Message'] = df['Message'].apply(preprocess_text)\n",
    "\n",
    "# Feature extraction and Encoding labels\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X = tfidf_vectorizer.fit_transform(df['Processed_Message'])\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(df['Category'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score      support\n",
      "ham            0.969128  0.997238  0.982982  1448.000000\n",
      "spam           0.978022  0.794643  0.876847   224.000000\n",
      "accuracy       0.970096  0.970096  0.970096     0.970096\n",
      "macro avg      0.973575  0.895940  0.929914  1672.000000\n",
      "weighted avg   0.970319  0.970096  0.968763  1672.000000\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(penalty='l2')  # Use L2 regularization\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "class_names = ['ham', 'spam']\n",
    "report = classification_report(y_test, y_pred, target_names=class_names, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "\n",
    "print(\"Classification Report:\\n\", report_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L2 regularization was chosen for the logistic regression model for several key reasons:\n",
    "\n",
    "1. **Stability and Convergence:** L2 provides a more stable solution that is less sensitive to small variations in the data, which helps to prevent model overfitting.\n",
    "\n",
    "2. **Improved Performance:** L2 generally enhances model performance by preventing coefficients from becoming excessively large, leading to better generalization.\n",
    "\n",
    "3. **Default Setting in Scikit-Learn:** L2 is the default regularization method in `scikit-learn`, making it a reliable and well-established choice.\n",
    "\n",
    "4. **Handling Correlated Features:** L2 effectively manages correlated features by applying the penalty more uniformly across them.\n",
    "\n",
    "5. **General Applicability:** L2 is advantageous when all features are expected to be relevant, as it applies a soft penalty without eliminating features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute confusion matrix\n",
    "class_names = ['ham', 'spam']\n",
    "cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
    "\n",
    "# Plot confusion matrix\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the evaluation of the logistic regression model using L2 regularization and SGDClassifier with the provided dataset, the following conclusions can be drawn:\n",
    "\n",
    "Model Performance:\n",
    "\n",
    "The logistic regression model with L2 regularization achieved a high accuracy of approximately 97%. The precision and recall for 'ham' messages are very high, indicating that the model is effective in identifying non-spam messages.\n",
    "For 'spam' messages, the precision is also high, but recall is somewhat lower, suggesting that while the model is good at identifying spam messages, there might be some spam messages that are not detected.\n",
    "The confusion matrix shows that the model performs well, with a small number of false positives and false negatives, confirming that the model's predictions are reliable.\n",
    "Regularization:\n",
    "\n",
    "Using L2 regularization helps in preventing overfitting by penalizing large coefficients, leading to a more generalized model.\n",
    "SGDClassifier:\n",
    "\n",
    "The SGDClassifier with logistic loss and L2 regularization provides a scalable alternative to logistic regression, particularly for large datasets. It showed comparable performance to the logistic regression model, demonstrating its efficiency and versatility.\n",
    "\n",
    "However, it is important to note that the data is not evenly distributed. As observed in the EDA, there are many more values in the \"ham\" category. This imbalance also influences the model's performance, leading to more errors in predicting the \"spam\" category.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
